\chapter{Introduction\label{chap:introduction}}
% \section{Machine Learning in Drug Discovery}
% Drug discovery is important. 
Drug discovery is the process of identifying and bringing to market new
medicines, which are a major contributor to our quality of life. However, the
process of bringing a new drug to market is a long, expensive, and risky endeavor.
Estimates of bringing a new drug to market range between 2.6 and xxx 
billion USD \citep{TODO}. When successful, however, a new drug can be a major source of
relief for patients.

% Traditional way of finding candidates.
One of the key challenges of the drug discovery process is the identification
of novel promising drug candidates. Traditionally, this is done by synthesizing
and testing the molecules efficacy in a laboratory and clinical studies. 
However, this process is usually very expensive, time-consuming and can be risky for 
patients. 

% ML can help to find promising candidates
Machine learning (ML) and deep learning (DL) have the potential to accelerate
the drug discovery process. Recent advances in ML, especially in the subfield of deep learning
have led to a surge in interest in applying ML and DL to drug discovery, 
culminating in breakthroughs such as AlphaFold \citep{TODO}. 
In this thesis, we focus on two key areas where ML and DL can help to accelerate
the drug discovery process: generative models for molecules and computer-aided
synthesis planning (CASP).

\section{Generative Models for Molecules}
% Generative models help to find promising candidates
{Goal-directed molecule generators} aim to address the challenge, of finding novel
molecular structures satisfying a property profile of interest. Given a computational scoring
function that encodes these properties, generative models create molecular
structures in a feedback loop, where the scoring function guides the generation
process. This contrasts with the traditional approach of virtual screening, where
a fixed virtual library of molecules is searched in a brute-force manner. This simple way 
of searching the chemical space is inefficient and is not able to 
tap into the possibilities provided by the vastness of drug-like chemical space, which is 
estimated to contain between $10^{23}$-$10^{60}$ molecules.
Generative models, on the other hand, hold the promise of being able to more efficiently find
promising drug candidates.

In contrast to these goal-directed models, \emph{distribution-learning} models aim to 
to learn the distribution of molecules in a dataset, and can then be used to 
sample novel molecules that resemble the distribution of the training data.
These models often form the basis of goal-directed models, as they can be pre-trained on a large
dataset of molecules \citep{segler,reinvent}. 

% The evaluation of generative models is challenging. 
However, the evaluation of generative models is challenging. This can mainly be attributed to
the fact that the generative tasks usually allow for multiple correct solutions and 
that the outputs of these models are usually complex, structured objects. 
In this thesis we focussed on the following aspects of evaluating generative models.

\paragraph{Evaluation of Distribution-Learning Models} The evaluation of distribution-learning
methods has posed challenges in different applications. While likelihood-based models, such as 
autoregressive models or flow-based models, can be evaluated using the negative log-likelihood, 
this metric is not available for other models, such as generative adversarial networks (GANs).
Therefore, alternative metrics have been proposed, such as the Frechet ChemNet Distance \citep{preuerFrechetChemNetDistance2018}
which has been included amoung others in the \emph{GuacaMol} \citep{brownGuacaMolBenchmarkingModels2019}
and \emph{MOSES} \citep{polykovskiyMolecularSets2018} distribution-learning benchmarks.

In \citep{renzFailureModesMolecule2019} we show the limitations of some commonly
used benchmarks for generative models for molecules. We show that the
\emph{GuacaMol} distribution-learning benchmark
\citep{brownGuacaMolBenchmarkingModels2019} is not able to distinguish between
sophisticated deep-learning models and a simple baseline model that generates
molecules by introducing minor variations of known molecules. 

\paragraph{Overfitting to machine learning based scoring functions} 
The scoring functions used in goal-directed generation tasks are often based on
machine learning models trained on experimental data. It is a well-known problem
that optimizing the inputs of discriminative machine learning model 
to maximize the class-probability of a certain class can lead to unsatisfactory results.
The generative models often optimize these outputs by adapting input features that 
are not actually relevant for the desired property. This can lead to overfitting to
artifacts of the scoring function and biased molecule generation.

In \citep{renzFailureModesMolecule2019} we address this issue, by introducing \emph{control scores} that give information
about whether the optimization overfits to "artifacts" of the scoring functions, 
by training additional scoring functions, with different random seeds and also on 
different subsets of available training data. Using this approach, 
we show how some popular generative models are heavily biased towards the exact training data
and how the optimization overfits to artifacts of the scoring function. \autoref{sec:failure-modes} 
reprints the corresponding publication.

\paragraph{Diversity focussed benchmark for generative models}
In many applications, it is crucial to generate a diverse, high-scoring sets of molecules. 
This is especially true in early stage drug discovery, where the goal is to find a wide variety of
promising drug candidates. This is because the used scoring functions are usually only an imperfect
approximation of the true properties of the molecules. Additionally some properties, are hard to model 
in-silico and are only discovered in the later stages of the drug discovery process.
This introduces a layer of uncertainty throughout the downstream stages of the drug discovery process. 
Finding a range of diverse candidates increases the success chances. However, little is known 
about how well existing approaches to diverse optimization perform in practice.
This is due to a combination of three main reasons. Firstly, many commonly used diversity metrics 
are inadequate for evaluating diverse optimization approaches. Secondly, a meaningful comparison of
optimization algorithms necessitates a standardized compute budget. 

In \citep{renzBenchmarkingEfficiencyGenerative2024} we introduce a benchmark 
for diverse optimization that addresses the above-mentioned issues. In this benchmark, we
evaluate the diversity of the generated molecules using a recently proposed diversity metric
\#Circles \citep{xie}. We compare the performance of diverse optimization approaches under two
different compute budgets, namely a fixed number of scoring function evaluations and a fixed time budget.
The first setting is relevant for applications where the cost of evaluating the scoring function 
dominates the optimization process, while the second setting is relevant for scoring functions that are
cheap to evaluate. 
Using this setup we test 14 goal-directed optimization methods and show how 
SMILES-based auto-regressive models dominate the benchmark. 
\autoref{sec:diverse-efficiency} reprints the corresponding publication.

\section{Retrosynthesis Prediction}
% Retrosynthesis planning is important and ML can help
Drug candidates, whether suggested by generative models or found by other means,
need at some point to be synthesized in a laboratory in order to be of any use.
To arrive at a desired molecule, often multiple steps of chemical reactions are
necessary. Computer-aided synthesis planning (CASP) aims to assist chemists in
this task. To arrive at a synthesis plan, CASP tools rely on computational
models of chemical reactions to predict which reactions can be used to
synthesize a target molecule. The quality of the synthesis plan depends heavily
on the accuracy of the used reaction model.

% A prominent approach to CASP is template-based planning
A prominent approach to CASP is template-based planning. In this approach
chemical reactions are modelled graph transformation rules, templates, that
encode connectivity changes between atoms during a chemical reaction.
This effectively reduces the reaction model to a classification problem, where
the goal is to predict which templates can be used to synthesize a target molecule.
However, this results in a large number of classes, with many classes only
represented by few training samples. This makes it difficult to train a model
that generalizes well for rare templates.

In \citep{seidlImprovingFewZeroShot2022} we study the problem of single-step
retrosynthesis prediction. Given a target molecule, the goal is to predict a
set of reactants that can be used to synthesize the target molecule.
Template-based models are a popular approach to single-step retrosynthesis
prediction. These models use so called reaction templates, which are
either extracted from a reaction database or hand-coded by a chemist.
Given a target molecule, the goal is then reframed as a classification task,
where the model predicts which templates can be used to synthesize the target.

While previous work has modelled the templates as distinct categories, we
propose a model that can leverage structural information about the templates.
For this we use a Modern Hopfield Network \citep{ramsauerHopfieldNetworksAll2020}, which
learns to associate relevant templates to product molecules.
This allows for generalization over templates and improves performance, especially
for templates with few training samples and even for unseen templates.

We could show that our models showed state-of-the-art performance in
the single-step retrosynthesis prediction task, and that our model is several
times faster than other methods.ddhtdhtdhtdhtdht

\paragraph{Can we improve the performance of reaction modelling using modern DL approaches?}
In \cref{sec:overview-mhn-react} we describe our work on improving the performance
of reaction modelling using a multimodal learning approach based on modern
Hopfield networks. The idea behind this approach is to learn relevant representations
of molecules and reaction templates and to associate them using a Hopfield network.
This allows for making use of similarities between templates and generalizing over
different templates instead of modelling them as distinct categories, leading to
improved performance, especially for templates with few training samples and even
for templates unseen during training.
The corresponding publication is reprinted in \cref{sec:mhn-react}.

\section{List of Papers}
This thesis comprises the work published in the following papers:

\begin{itemize}
    \item \fullcite{renzFailureModesMolecule2019}
    \item \fullcite{renzBenchmarkingEfficiencyGenerative2024}
    \item \fullcite{seidlImprovingFewZeroShot2022}
\end{itemize}

% give overview over my other publications
\paragraph{Other Publications} Besides the papers listed above, I have also
contributed to the following publications:

\begin{itemize}
    \item \fullcite{preuerFrechetChemNetDistance2018}
    \item \fullcite{renzUncertaintyEstimationMethods2019}
    \item \fullcite{hofmarcherLargescaleLigandbasedVirtual2020}
    \item \fullcite{renzLowCountTimeSeries2023}
\end{itemize}