\chapter{Introduction\label{chap:introduction}}
% Drug discovery is important. 
Drug discovery is the process of identifying new medicines and bringing them to
market. The discovery of novel pharmaceutical treatments has been a major driver
of quality of life over the centuries. While the discovery of new drugs has started 
in serendipitous and lucky discoveries, enabled by advances in our understanding of 
chemistry, bio-chemistry and molecular biology and new technologies, the process has
become more systematic and data-driven over the last decades. The invention of 
new drugs has been - and still is - a major driver of quality of life.

% Traditional way of finding candidates.
One of the key challenges of the drug discovery process is the identification
of novel promising drug candidates, which are often small molecules, like for example 
aspirin or penicillin. The efficacy of a drug is usually determined by its ability
to interact with a biological target in the body. To find such molecules,
the traditional approach is to synthesize and test the molecules efficacy first in laboratory
experiments, and finally in clinical studies. However, this process is usually very expensive, time-consuming
and involves risks for patients.

% Computer aided drug discovery
Computer aided drug discovery (CADD) aims to accelerate the drug discovery process
by using computational methods. Applications range from basic chemical information 
processing, over physical simulation of molecular interactions, to sophisticated 
machine learning methods. The latter have shown great progress in recent years,
especially driven by advances in deep learning \citep{todo}. The field has seen 
breakthroughs in many areas, including protein structure prediction achieved by AlphaFold \citep{todo}, 
chemical property prediction \citep{mayrDeepToxToxicityPrediction2016,todo}, retrosynthesis planning \citep{seglerNeuralSymbolicMachineLearning2017} and
molecule generation \citep{todo}. What these methods have in common is that they
all help in reducing the need for expensive and time-consuming wet-lab experiments, 
by providing accurate computational models of the drug-target interaction, enabling 
new ways of exploring chemical space by providing new tools for chemists to
design and synthesize new molecules.

% Significance and objectives of the thesis
In this thesis, we focus on two key areas where machine learning can help to accelerate
the drug discovery process: generative models for molecules and computer-aided
synthesis planning (CASP). Generative models for molecules aim to find novel
molecular structures satisfying a property profile of interest. These models 
have been shown to be able to generate stable chemical structures and have been
used to generate novel drug candidates. However, the evaluation of generative 
models is challenging, as the outputs of these models are usually complex, structured
objects, and there are often no straightforward ways to evaluate the quality or relevance 
of the generated molecules. In this thesis, we address this issue by proposing new
evaluation metrics and benchmarks for generative models.

% CASP
Computer-aided synthesis planning (CASP) aims to assist chemists in the task of
synthesizing a target molecule. Using a computational model of chemical
reactions, combined with search algorithms, CASP tools can suggest synthesis
plans for a molecule of interest. The model of chemical reactions is crucial for
the performance of CASP tools and is based on machine learning models, trained 
on reaction databases. In this thesis, we address the problem of single-step
retrosynthesis prediction, where the goal is to predict a set of reactants that
can be used to synthesize a target molecule. We propose a novel approach to
template-based retrosynthesis prediction, based on modern Hopfield networks,
which allows for generalization over templates and improves performance, especially
for templates with few training samples and even for unseen reaction templates.

% PROMISE
This thesis is structured as follows. In \cref{sec:generative-models} we give 
an overview of generative models for molecules, discuss the challenges of evaluating
these models and present our contributions to this field. In \cref{sec:retrosynthesis}
we give a short overview of computer-aided synthesis planning and outline our contributions. 
\Cref{sec:publications} lists the publications that are part of this thesis and 
some of my other publications. \Cref{chap:publications} reprints the publications
and their corresponding supplementary material. Finally, \cref{chap:conclusion} concludes
the thesis and gives an outlook on future work.



% \begin{minipage}
% : Rational drug discovery.
% This approach starts with the identification of a biological target in the body 
% which is hypothesized to be associated with a disease phenotype. 
% One then attempts to find a small molecule that can change the activity of 
% the target in the desired way. While this way of searching for new drugs 
% is more direct than phenotypic drug discovery the identification of 
% drug targets can be challenging and given the complex interconnectedness 
% of biochemical pathways, it is not fully understood how some drugs work, 
% which goes even for highly popular ones.

% Phenotypic drug discovery takes this trial-and-error approach and applies it 
% in a systematic manner. The focus in this approach, which is also called forward 
% pharmacology, lies on screening collections of small molecules or other potential 
% medicines for pharmaceutical effects. Once a pharmacologically active molecule 
% has been found the aim is to discover how to use it's effect therapeutically. 
% This process can proceed without knowing the biochemical mode of action, of how 
% a drug actually achieves its effect. 

% How were new medicines discovered?
% David C. Swinney & Jason Anthony 
% Lots of molecules also by phenotypic screening

% One of core goals in both approaches is to find molecules with a desired
% pharmacological profile, which includes primarily the ability of a molecule to
% modify a target, but also other important
% properties, e.g. absorption, distribution, metabolism, excretion or toxicity. 
% To find such molecules, specially designed wet-lab experiments called \emph{assays} 
% are usually use to measure these properties of interest. The number of tested 
% molecules can range from numbers in the tens to millions of tested molecules
% in high-througput screening. 

% \emph{Computer-aided drug design} aims to reduce the need 
% for these expensive experiments using computational methods. 
% The field of quantitative structure activity/property relationship (QSAR/QSPR)
% aims to find an accurate computational model of the drug-target interaction. 
% Structure-based methods make use of the known structures of the drug and target 
% and calculate binding affinity using physical modelling. 
% In contrast, ligand-based methods find links between molecular structures
% and measured experimental outcomes. In recent years, machine learning methods 
% have shown great promise at modelling these relationships. 
% Using these models one can prioritize which of the molecules available in a screening 
% collection to test next, to avoid wasting ressources on unpromising compounds.

% However, this approach of virtual screening is limited to existing screening collections
% and computational constraints. The $~10^{12}$ \citep{todo} molecules that can be realistically 
% evaluated fall far short of the $10^{23}$-$10^{60}$ drug-like molecules 
% which are estimated to exist \citep{todo}, and necessarily miss out on promising drug candidates.
% Generative models aim to alleviate this problem, by using the QSAR/QSPR function as a guiding signal 
% in order to be able to explore chemical space in a goal-directed manner. 
% The evaluation 

% However, the process of bringing a new drug to market is a long, expensive, and risky endeavor.
% Estimates of bringing a new drug to market range between 2.6 and xxx 
% billion USD \citep{todo}. When successful, however, a new drug can be a major source of
% relief for patients.

% % Traditional way of finding candidates.
% One of the key challenges of the drug discovery process is the identification
% of novel promising drug candidates. Traditionally, this is done by synthesizing
% and testing the molecules efficacy in a laboratory and clinical studies. 
% However, this process is usually very expensive, time-consuming and can be risky for 
% patients. 

% % ML can help to find promising candidates
% Machine learning (ML) and deep learning (DL) have the potential to accelerate
% the drug discovery process. Recent advances in ML, especially in the subfield of deep learning
% have led to a surge in interest in applying ML and DL to drug discovery, 
% culminating in breakthroughs such as AlphaFold \citep{todo}. 
% In this thesis, we focus on two key areas where ML and DL can help to accelerate
% the drug discovery process: generative models for molecules and computer-aided
% synthesis planning (CASP).
% \end{minipage}

\section{Advancing the Evaluation of Generative Models for Molecules\label{sec:generative-models}}
% Generative models help to find promising candidates
Goal-directed molecule generators aim to address the challenge, of finding novel
molecular structures satisfying a property profile of interest. Given a computational scoring
function that encodes these properties, generative models create molecular
structures in a feedback loop, where the scoring function guides the generation
process. This contrasts with the traditional approach of virtual screening, where
a fixed virtual library of molecules is searched in a brute-force manner. This simple way 
of searching the chemical space is inefficient and is not able to 
tap into the possibilities provided by the vastness of drug-like chemical space, which is 
estimated to contain between $10^{23}$-$10^{60}$ molecules.
Generative models, on the other hand, hold the promise of being able to more efficiently find
promising drug candidates.

The field of generative models for molecules has seen a surge in interest in
recent years, driven by advances in deep learning, especially in the field of
natural language processing. The first deep-learning based generative models for
molecules were based on recurrent neural networks (RNNs) originally popularized
for text generation. After this early work by
\citep{seglerGeneratingFocusedMolecule2018} and
\citep{gomez-bombarelliAutomaticChemicalDesign2018} a great number of different
models have been proposed
\citep{eltonDeepLearningMolecular2019,sanchez-lengelingInverseMolecularDesign2018}.
The model types include autoregressive models, generative adversarial networks
(GANs), variational autoencoders (VAEs), flow-based models
\citep{madhawaGraphNVPInvertibleFlow2019}. Another design choice is the
representation of the molecules, which can be based on SMILES strings,
graph-based representations or 3D structures
\citep{eltonDeepLearningMolecular2019,sanchez-lengelingInverseMolecularDesign2018}.

Generative models are often divided into two categories: \emph{goal-directed}
and \emph{distribution-learning} models. Distribution-learning models learn
general structural patterns in molecules and aim to sample novel molecules that
the training data in distribution. These models are then most often used as a
basis for goal-directed models, which aim to find molecules that satisfy a
property profile of interest. This property profile can include a range of
properties, including the activity against a target, or other important traits
such as solubility or toxicity. These properties are usually encoded in a
scoring function, which is then used to guide the generation process, in a
reinforcement learning style feedback loop.

% The evaluation of generative models is challenging. 
While generative models have shown great promise in generating stable chemical
structures their evaluation is often challenging. Where in discriminative tasks
the evaluation is usually straightforward, as the model outputs a single
prediction, the evaluation of generative models requires consideration of
various aspects of the generated molecules. This has led to the development of a
range of evaluation metrics \citep{preuerFrechetChemNetDistance2018,gaoSynthesizabilityMoleculesProposed2020} and
benchmarks for generative models
\citep{polykovskiyMolecularSetsMOSES2020,brownGuacaMolBenchmarkingModels2019}.
However, the evaluation of generative models is still an active area of research
and challenges remain. In this thesis, we address some of these challenges 
which are outlined in the following sections.

\subsection{Evaluation of Distribution-Learning Models}
The evaluation of distribution-learning methods has posed challenges in
different applications, apart from the generation of molecules. While so called
\emph{likelihood-based} models, such as autoregressive models or flow-based
models, can be evaluated using metrics such as the negative log-likelihood or
perplexity evaluated on a hold-out test set, 
other models such as generative adversarial networks (GANs)
\citep{goodfellowGenerativeAdversarialNetworks2014} do not offer the possibility of
such a straightforward evaluation. To this end alternative metrics have been proposed, 
spawning its own subfield of research \citep{heuselGANsTrainedTwo2017}.

In the field of cheminformatics new metrics have been proposed to evaluate the
quality of generated molecules and how well they match the training data in
distribution \citep{preuerFrechetChemNetDistance2018}.
\citet{polykovskiyMolecularSetsMOSES2020} and
\citet{brownGuacaMolBenchmarkingModels2019} introduced the Moses and GuacaMol
benchmarks respectively, which evaluate the quality of generated molecules using
a combination of metrics. Among these are the FCD metric
\citep{preuerFrechetChemNetDistance2018}, the internal diversity
\citep{benhendaChemGANChallengeDrug2017} of the generated molecules, or the
KL-divergence between the distributions of chemico-physical properties of the
generated molecules and the training data.

It is however not clear how informative these metrics actually are and how well
they correlate with the actual usefulness of the tested generative models. In
\citep{renzFailureModesMolecule2019} (\cref{sec:failure-modes}) we show the
limitations of the GuacaMol distribution-learning benchmark, by evaluating the
performance of different sophisticated generative models on this benchmark, and
comparing it to a simple baseline model that generates molecules by introducing
minor variations of the molecules in the training data. We show that the 
most of the tested generative models do not outperform the simple baseline
model, or only do so marginally. This suggests that the current benchmarks
might not be able to capture the actual usefulness of current generative models 
in distribution-learning tasks.

\subsection{Overfitting to Scoring Functions Biases in Goal-Directed Generation}
In goal-directed generation tasks, the generative models are trained to optimize
a scoring function that encodes the desired properties of the generated
molecules. The scoring functions used in these tasks are often based on machine
learning models trained on experimental data. This can lead to problems, as the 
optimization process can overfit to biases of the scoring function. This can
lead to two separate problems: Firstly, the generative models can overfit to
artifacts of the scoring function, which are not actually relevant for the
modelled property. Secondly, the generative models may overfit to the data 
used to train the scoring function, which can lead to a lack of novely in the
generated molecules.

The scoring functions used in goal-directed generation tasks are often based on
machine learning models trained on experimental data. It is a well-known problem
that optimizing the inputs of discriminative machine learning model 
to maximize the class-probability of a certain class can lead to unsatisfactory results.
The generative models often optimize these outputs by adapting input features that 
are not actually relevant for the desired property. This can lead to overfitting to
artifacts of the scoring function and biased molecule generation.

In \citep{renzFailureModesMolecule2019} we introduce \emph{control scores} that
give information whether the optimization overfits to "artifacts" of the scoring
functions, or the training data. We do this by training additional scoring
functions, with different random initialization and also on a hold-out subset of
the available training data. Using this approach, we can show that some popular
generative models overfit to features of the scoring function unique to the
initialization and training data. This suggests that the reported performance of
these models might be biased and overestimate the actual performance of the
models. We also show that indeed the generation is biased towards the training
data which can lead to a lack of novelty in the generated molecules.
\Cref{sec:failure-modes} reprints the corresponding publication.

\subsection{Diversity-based benchmarking of Goal-Directed Generators\label{sec:divopt}}
% Why is diversity important?
The diversity of the generated molecules is an important aspect in the
application of goal-directed generative models. Given that the scoring functions
are usually only an imperfect and incomplete approximation of the desired
properties, finding a diverse set of molecules that score well can increase the
success chancess of downstream stages of the drug discovery project. Given the
expected failure of some of the candidates in later experiments, having a backup
of other candidates with somewhat different structure can be beneficial.

It is unclear how well current generative models perform in generating diverse
high-scoring molecules, which is due to a combination of two main factors. 
Firstly, many commonly used diversity metrics are inadequate for evaluating
diverse optimization approaches. This results in uninformative benchmarks that
do not meaningfully measure the diversity of the generated molecules. Secondly,
a meaningful comparison of goal-directed generators necessitates a standardized
compute budget. This is because the performance of generative models depends strongly 
on the amount of ressources available for training and evaluation.

In \citep{renzBenchmarkingEfficiencyGenerative2024} we introduce a benchmark for
diverse optimization that addresses the above-mentioned issues. In this
benchmark, we evaluate the diversity of the generated molecules using a recently
proposed diversity metric \#Circles \citep{xieHowMuchSpace2023}. We compare the
performance of diverse optimization approaches under two different compute
budgets, namely a fixed number of scoring function evaluations and a fixed time
budget. The first setting is relevant for applications where the cost of
evaluating the scoring function dominates the optimization process, while the
second setting is relevant for scoring functions that are cheap to evaluate.
Using this setup we test 14 goal-directed optimization methods and show how
SMILES-based auto-regressive models dominate the benchmark.
\Cref{sec:diverse-efficiency} reprints the corresponding publication.

\section{Retrosynthesis Prediction\label{sec:retrosynthesis}}
% Retrosynthesis planning is important and ML can help
Drug candidates, whether suggested by generative models or found by other means,
need at some point to be synthesized in a laboratory in order to be of any use.
To arrive at a desired molecule, often multiple steps of chemical reactions are
necessary. Computer-aided synthesis planning (CASP) aims to assist chemists in
this task. To arrive at a synthesis plan, CASP tools rely on computational
models of chemical reactions to predict which reactions can be used to
synthesize a target molecule. The quality of the synthesis plan depends heavily
on the accuracy of the used reaction model.

% A prominent approach to CASP is template-based planning
A prominent approach to CASP is template-based planning. In this approach
chemical reactions are modelled graph transformation rules, templates, that
encode connectivity changes between atoms during a chemical reaction.
This effectively reduces the reaction model to a classification problem, where
the goal is to predict which templates can be used to synthesize a target molecule.
However, this results in a large number of classes, with many classes only
represented by few training samples. This makes it difficult to train a model
that generalizes well for rare templates.

In \citep{seidlImprovingFewZeroShot2022} we study the problem of single-step
retrosynthesis prediction. Given a target molecule, the goal is to predict a
set of reactants that can be used to synthesize the target molecule.
Template-based models are a popular approach to single-step retrosynthesis
prediction. These models use so called reaction templates, which are
either extracted from a reaction database or hand-coded by a chemist.
Given a target molecule, the goal is then reframed as a classification task,
where the model predicts which templates can be used to synthesize the target.

While previous work has modelled the templates as distinct categories, we
propose a model that can leverage structural information about the templates.
For this we use a Modern Hopfield Network \citep{ramsauerHopfieldNetworksAll2020}, which
learns to associate relevant templates to product molecules.
This allows for generalization over templates and improves performance, especially
for templates with few training samples and even for unseen templates.

We could show that our models showed state-of-the-art performance in
the single-step retrosynthesis prediction task, and that our model is several
times faster than other methods.ddhtdhtdhtdhtdht

\paragraph{Can we improve the performance of reaction modelling using modern DL approaches?}
In \cref{sec:overview-mhn-react} we describe our work on improving the performance
of reaction modelling using a multimodal learning approach based on modern
Hopfield networks. The idea behind this approach is to learn relevant representations
of molecules and reaction templates and to associate them using a Hopfield network.
This allows for making use of similarities between templates and generalizing over
different templates instead of modelling them as distinct categories, leading to
improved performance, especially for templates with few training samples and even
for templates unseen during training.
The corresponding publication is reprinted in \cref{sec:mhn-react}.

\section{List of Publications\label{sec:publications}}
This thesis comprises the work published in the following papers:

\begin{itemize}
    \item \fullcite{renzFailureModesMolecule2019}
    \item \fullcite{renzBenchmarkingEfficiencyGenerative2024}
    \item \fullcite{seidlImprovingFewZeroShot2022}
\end{itemize}

% give overview over my other publications
\paragraph{Other Publications} Besides the papers listed above, I have also
contributed to the following publications:

\begin{itemize}
    \item \fullcite{preuerFrechetChemNetDistance2018}
    \item \fullcite{renzUncertaintyEstimationMethods2019}
    \item \fullcite{hofmarcherLargescaleLigandbasedVirtual2020}
    \item \fullcite{renzLowCountTimeSeries2023}
\end{itemize}